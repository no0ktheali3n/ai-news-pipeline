# ğŸ“œ CHANGELOG.md  
**Project:** `scraper-alpha`  
**Maintainer:** no0ktheali3n  
**Created:** April 2025  
**Purpose:** Version-controlled AI research scraper, summarizer, and social media poster pipeline

---

### ğŸŸ¦ [v0.4.5] â€“ Summarizer Lambda & Chunked Orchestration

- ğŸ§  Introduced `summarizer_lambda.py`, receiving chunked input via Lambda events
- ğŸ“š Refactored summarizer to combine summary + hashtag into one Claude 3.5 Sonnet prompt
- ğŸ” Built `utils/orchestrator.py`:
  - `split_into_chunks()` â€“ divides full scrape dataset into discrete chunks
  - `invoke_lambda_for_chunk()` â€“ asynchronously triggers summarizer lambdas
  - `reassemble_chunks_from_s3()` â€“ rebuilds full article set from S3 output
- ğŸ§ª Implemented retry logic with jittered delay for Claude Bedrock throttling
- âš™ï¸ Added `run_id` timestamp logic to group chunk outputs under unique run sessions
- ğŸ“‚ Reassembled output now sorted by chunk index, not S3 write time
- ğŸ“¤ Uploaded final merged JSON to `final_summarized_<run_id>.json` in S3
- ğŸ“¤ Integrated orchestrator summarizer into `template.yml`

> Achieves full orchestration of distributed summarization with reassembled output ready for posting

---

### ğŸŸ¦ [v0.4.4] â€“ Scraper Lambda Deployment

- ğŸ› ï¸ Adjusted `scraper.py` and generated `scraper_lambda.py` for Lambda compatibility
- ğŸª£ Configured dynamic article limits + S3 output pathing using environment variables
- ğŸ” Ensured proper IAM permissions for `s3:PutObject` scoped to `ScraperOutputPrefix`
- âœ… Verified scraper Lambda works independently and writes to correct S3 prefix
- ğŸ“¦ Integrated scraper, summarizer, poster into `template.yaml` for `sam build && sam deploy`

> First Lambda module deployed into production with cloud-native output handling

---

### ğŸš€ [v0.4.3] â€” AWS Deployment and IAM Architecture

- ğŸ“¦ Deployed full Lambda pipeline to AWS via SAM:
  - `scraper_lambda.py`
  - `summarizer_lambda.py`
  - `poster_lambda.py`
- ğŸ” Created and attached IAM user groups for:
  - `ai-pipeline-admin` with full Lambda/IAM/SecretsManager privileges
  - `ai-pipeline-contributor` with scoped log and secrets access
- ğŸ§¾ Refined `template.yaml` to define:
  - All Lambda functions with separate roles
  - Environment configuration (excluding reserved AWS keys)
  - Outputs for live ARNs
- ğŸ§ª Verified working deployment with `sam build && sam deploy`
- âœ… Rolled back and resolved permission errors related to:
  - `iam:CreateRole`, `iam:AttachRolePolicy`, tagging constraints
  - AWS reserved variable `AWS_REGION` conflict

> This version marks the full lift of the local stack into a cloud-native structure and sets the foundation for unified orchestration in `v0.5.0`.


## [v0.4.2] - 2025-04-14
### âœ¨ Enhancements & Polish
- âœ… Added support for `--dry-run` flag to preview tweet threads without posting.
- âœ… Added `--variant` CLI argument for summary style selection (defaults to `v1_summary`).
- âœ… Integrated structured logging using Pythonâ€™s `logging` module:
  - Logs to both console and rotating file (`poster_pipeline.log`).
  - Configurable log level via `.env` (`LOG_LEVEL=INFO`, `DEBUG`, etc.).
- âœ… Implemented `.env` validation to check for required Twitter credentials before posting.
- âœ… Archived `summarized_output.json` to timestamped file in `/archive/` after successful post.
- âœ… Preserved user-facing `print()` statements for notebook/debug use, while logging in parallel.
- âœ… Consistently separated CLI and Lambda logic.

### ğŸ§¹ Cleanup
- âœ… Moved logger setup into reusable `utils/logger.py` module.
- âœ… Ensured `.env.example` is updated with `LOG_LEVEL`.

### ğŸ“‚ Files Affected
- `utils/post_to_twitter.py`
- `utils/logger.py`
- `.env.example`
- `CHANGELOG.md`

---

ğŸ¯ This version completes our local CLI polish sprint. Next up: Deployment, CI/CD, and Bedrock Secrets Manager integration.


## [v0.4.1] - 2025-04-13
### ğŸ‰ Added
- âœ… **Tweet threading fully operational** â€“ Entire article summaries are now posted as threads via Tweepy.
- âœ… **`post_to_twitter.py`** implemented for posting from `summarized_output.json`.
- âœ… **`twitter_threading.py`** added to utils for generating properly chunked tweet threads.
- âœ… Interactive preview with character counts and user prompt before posting.
- âœ… Basic retry delay handling and graceful failure logging.

### âœ… Validated
- Full end-to-end test completed: single-thread article summary successfully posted to Twitter.
- Verified that posting works for both first tweet and all replies using v2 API.

### ğŸ›  Internal
- Resolved `403 Forbidden` errors by switching fully to `Client.create_tweet()` in Tweepy v4+.
- Updated Tweepy utility to use environment-loaded credentials correctly.
- Fixed module import errors by modifying `sys.path` and restructuring import paths.


## [v0.4.0] - 2025-04-12
### Added
- `utils/tweepy_client.py`: Modular Tweepy integration with support for tweet threading and test CLI.
- `.env.example`: OAuth1.0a token variables required for Twitter posting.
- Poster logic now exports tweet metadata to both JSON and CSV.
- First successful tweet posted via Tweepy client.

### Changed
- Finalized poster formatting logic to prioritize clarity and character-efficient summaries.

### Notes
- Twitter posting currently uses OAuth1.0a with v2 endpoint (`create_tweet`).
- Future upgrades may include OAuth2 flow and media/alt text support.
- Future upgrades will move to integrate poster into AI summary pipeline.


## [v0.3.0] - (2025-04-11)
### âœ¨ Added
- Claude-powered summarizer module with AWS Bedrock integration.
- Prompt templates for v1 (social/engaging) and v2 (technical/concise) summaries.
- Hashtag generation via Claude and appended to summary metadata.
- Retry mechanism for throttling errors with exponential backoff and jitter.
- Full local support via `.env` environment variables.
- Logging of estimated token usage and model version.
- Jupyter-based prompt testing in `notebooks/summarization-lab.ipynb`.

### ğŸ› ï¸ Changed
- Refined `.env.example` with Bedrock-specific placeholders.
- Added summary and hashtag fields to `summarized_output.json` format for downstream poster usage.

### ğŸ§ª Testing
- Summarizer tested with Claude 3.5 Sonnet on AWS Bedrock.
- Manual validation of summary accuracy, hashtag quality, and retry behavior.

### ğŸ” Security
- Secret keys moved to `.env` and properly excluded via `.gitignore`.
- AWS IAM user/role configured with Bedrock access policy.

---

âœ… This version completes the **AI Summarization Layer** for the pipeline. The next milestone (`v0.4.0`) will finalize tweet formatting and prepare for Tweepy/X API integration.

## âœ… [v0.2.1] â€“ (2025-04-10)  
### Summary  
Stabilized and security-hardened scraper pipeline. Removed secret key exposure, added `.env.example`, implemented auto-versioning, and tested summarizer + poster locally. Streamlined ArXiv article parsing and improved output consistency.

### âœ… Added  
- `.env.example` template for secure environment setup  
- `.gitignore` to prevent secrets from being committed  
- Auto-trimming of tweets for 280-character Twitter formatting  
- Dynamic hashtag generation from summarizer output  
- Claude Sonnet 3.5 Bedrock integration for summarization  
- Retry logic for Bedrock API throttling  
- Jupyter notebooks for summarizer and poster module previews  

### ğŸ› ï¸ Fixed  
- **Redundant URL bug**: `base_url + href` caused malformed links  
  - **Fix**: Removed `base_url` in `scraper.py` logic  
- **AWS keys pushed accidentally**  
  - Secrets were detected by GitHub Push Protection  
  - BFG Repo Cleaner used with `--no-blob-protection` to scrub history  
  - `.env` untracked and `.env.example` introduced  
- **VSCode module resolution issue (`utils` not found)**  
  - Fixed by appending project root to `sys.path`  
- **Virtual environment activation error in PowerShell**  
  - Resolved by setting execution policy to `RemoteSigned`  
- **FileNotFoundError in summarizer/poster notebooks**  
  - Fixed by dynamically resolving path via `os.path.join(__file__)`  
- **Throttling from Claude API (Bedrock)**  
  - Implemented exponential backoff and graceful retry logic  

### ğŸ” Security Actions  
- Verified no real secrets were committed (`git log -p | Select-String`)  
- Enabled GitHub Secret Scanning and Push Protection  
- Revoked and rotated AWS credentials  
- Ensured `.env` is now untracked and ignored  

---

## ğŸ§ª [v0.2.0] â€“ Initial Refactor Commit (Pre-Release)

### Summary  
Refactored `scraper-alpha` from a simple prototype into a modular pipeline. Introduced structure, utilities, and isolated web scraping logic into a dedicated `ScraperClient` class.

### âœ… Added  
- `ScraperClient` class with configurable target URL  
- `utils/user_agents.py` for rotating user agents  
- `utils/request_helpers.py` for random request delays  
- Initial scraping logic for ArXiv articles (AI + CS filters)  
- Article parsing for title, link, authors, and abstract snippet  
- Export to `test_output.json`  
- Tagged pre-release as `v0.2.0`  

### âš ï¸ Known Issues at the Time  
- Redundant URL bug (later fixed in `v0.2.1`)  
- No environment variable management or `.env` file structure  
- No LLM integration or summarization/posting modules  

---

## ğŸ“Œ Notable Development Events

- **Claude v3.7 Bedrock error**  
  > `Invocation with on-demand throughput isnâ€™t supported.`  
  - âœ… Switched to Claude 3.5 Sonnet for reliable support

- **Push Protection Triggers**  
  - âœ… GitHub blocked commit before secrets reached remote  
  - âœ… BFG Repo Cleaner used to wipe historical traces

- **Jupyter Notebook adoption**  
  - âœ… Chosen for previewing summarizer and poster logic outside Lambda

- **VSCode edge-case interpreter issues**  
  - âœ… Confirmed interpreter path manually  
  - âœ… Switched to CLI-only execution in some test cases

---

## [v0.1.0] â€“ 2023-10
### ğŸ›  Prototype
- Initial scraper built using BeautifulSoup.
- First version very basic, manually developed to automate scraping general data 

---

