{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "669e26d6-e632-4784-a284-e69d0f9f613f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tweet 1 ---\n",
      "Sculpting Subspaces: Constrained Full Fine-Tuning in LLMs for Continual Learning\n",
      "\n",
      "https://arxiv.org/abs/2504.07097\n",
      "#AI #ContinualLearning #LLM #CatastrophicForgetting #AdaptiveSVD #AIFineTuning\n",
      "Characters: 193\n",
      "\n",
      "--- Tweet 2 ---\n",
      "Are We Done with Object-Centric Learning?\n",
      "\n",
      "https://arxiv.org/abs/2504.07092\n",
      "#AI #ObjectCentricLearning #ComputerVision #AIRepresentation #OODGeneralization #OCCAM\n",
      "Characters: 162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# poster-lab.ipynb â€“ Final Fix: Summary Now Included, Trimmed Properly\n",
    "\n",
    "import json\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "# Constants and paths\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "SUMMARY_PATH = os.path.join(PROJECT_ROOT, \"summarized_output.json\")\n",
    "DEFAULT_HASHTAGS = [\"#AI\"]\n",
    "MAX_TWEET_LENGTH = 280\n",
    "\n",
    "# Load summarized articles\n",
    "try:\n",
    "    with open(SUMMARY_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        articles = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"[ERROR] summarized_output.json not found at: {SUMMARY_PATH}\")\n",
    "    articles = []\n",
    "\n",
    "def format_tweet(article, variant=\"v1_summary\", include_hashtags=True):\n",
    "    title = article.get(\"title\", \"\").strip()\n",
    "    summary = article.get(variant, \"\").strip()\n",
    "    url = article.get(\"url\", \"\").strip()\n",
    "\n",
    "    # Extract dynamic hashtags and merge with static\n",
    "    dynamic_tags = [tag for tag in article.get(\"hashtags\", \"\").split() if tag.startswith(\"#\")]\n",
    "    all_tags = list(dict.fromkeys(DEFAULT_HASHTAGS + dynamic_tags))  # remove duplicates, preserve order\n",
    "    hashtag_block = \" \".join(all_tags) if include_hashtags else \"\"\n",
    "\n",
    "    # Compose full tweet before trimming\n",
    "    full = f\"{title}\\n{summary}\\n{url}\\n{hashtag_block}\".strip()\n",
    "\n",
    "    # Trim summary only if tweet exceeds limit\n",
    "    if len(full) > MAX_TWEET_LENGTH:\n",
    "        reserved = len(title) + len(url) + len(hashtag_block) + 3  # +3 for line breaks\n",
    "        max_summary_len = MAX_TWEET_LENGTH - reserved\n",
    "        trimmed_summary = textwrap.shorten(summary, width=max_summary_len, placeholder=\"...\")\n",
    "        full = f\"{title}\\n{trimmed_summary}\\n{url}\\n{hashtag_block}\".strip()\n",
    "\n",
    "    return full\n",
    "\n",
    "# Preview formatted tweets\n",
    "for i, article in enumerate(articles[:3]):\n",
    "    tweet = format_tweet(article)\n",
    "    print(f\"--- Tweet {i+1} ---\\n{tweet}\\nCharacters: {len(tweet)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae021889-98de-4658-af2e-b80916de4043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a2c3c-08c0-4bf3-a778-1ffe2bec5b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
