{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669e26d6-e632-4784-a284-e69d0f9f613f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tweet 1 (v1_summary) ---\n",
      "URECA: Unique Region Caption Anything\n",
      "ðŸ“¸âœ¨ Ever wished your photos could talk? Meet URECA, the AI that's giving image regions a voice! ðŸ—¨ï¸ This clever system can describe any part of a...\n",
      "https://arxiv.orghttps://arxiv.org/abs/2504.05305\n",
      "#AI #RegionCaptioning #ComputerVision #MultimodalAI #ImageUnderstanding #URECA\n",
      "\n",
      "Characters: 313\n",
      "\n",
      "--- Tweet 1 (v2_summary) ---\n",
      "URECA: Unique Region Caption Anything\n",
      "This research paper introduces URECA, a novel approach to region-level image captioning that addresses limitations in existing methods,...\n",
      "https://arxiv.orghttps://arxiv.org/abs/2504.05305\n",
      "#AI #RegionCaptioning #ComputerVision #MultimodalAI #ImageUnderstanding #URECA\n",
      "\n",
      "Characters: 305\n",
      "\n",
      "--- Tweet 2 (v1_summary) ---\n",
      "SmolVLM: Redefining small and efficient multimodal models\n",
      "ðŸ“±ðŸ¤– Honey, I shrunk the AI! Meet SmolVLM, the tiny but mighty vision-language model that packs a big punch in a small package. ðŸ¥ŠðŸ’ª This little genius outperforms models...\n",
      "https://arxiv.orghttps://arxiv.org/abs/2504.05299\n",
      "#AI #SmolVLM #EfficientAI #MultimodalML #CompactVLM #EdgeAI\n",
      "\n",
      "Characters: 337\n",
      "\n",
      "--- Tweet 2 (v2_summary) ---\n",
      "SmolVLM: Redefining small and efficient multimodal models\n",
      "Key points from the research paper: 1. Novel approach: SmolVLM, a series of compact multimodal models designed for resource-efficient inference on mobile and edge...\n",
      "https://arxiv.orghttps://arxiv.org/abs/2504.05299\n",
      "#AI #SmolVLM #EfficientAI #MultimodalML #CompactVLM #EdgeAI\n",
      "\n",
      "Characters: 333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# poster-preview.ipynb (Tweet formatter notebook with Claude + static + dynamic hashtags)\n",
    "\n",
    "import json\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "# Paths and default constants\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..'))\n",
    "SUMMARY_PATH = os.path.join(PROJECT_ROOT, \"summarized_output.json\")\n",
    "DEFAULT_HASHTAGS = [\"#AI\"]  # Always include this for visibility\n",
    "MAX_TWEET_LENGTH = 280\n",
    "\n",
    "# Load summarized data\n",
    "try:\n",
    "    with open(SUMMARY_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        articles = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Could not find summarized_output.json at: {SUMMARY_PATH}\")\n",
    "    articles = []\n",
    "\n",
    "# Format tweet\n",
    "\n",
    "def format_tweet(article, variant=\"v1_summary\", include_hashtags=True):\n",
    "    title = article.get(\"title\", \"\")\n",
    "    summary = article.get(variant, article.get(\"summary\", \"\"))\n",
    "    url = article.get(\"url\", \"\")\n",
    "\n",
    "    # Extract Claude-suggested hashtags and merge with defaults\n",
    "    dynamic = article.get(\"hashtags\", \"\")\n",
    "    all_tags = DEFAULT_HASHTAGS.copy()\n",
    "    if dynamic:\n",
    "        dynamic_tags = [tag for tag in dynamic.split() if tag.startswith(\"#\") and tag not in all_tags]\n",
    "        all_tags.extend(dynamic_tags)\n",
    "    hashtags = \" \".join(all_tags) if include_hashtags else \"\"\n",
    "\n",
    "    base = f\"{title}\\n{summary}\\n{url}\"\n",
    "    full_tweet = f\"{base}\\n{hashtags}\".strip()\n",
    "\n",
    "    # Trim if needed\n",
    "    if len(full_tweet) > MAX_TWEET_LENGTH:\n",
    "        allowable = MAX_TWEET_LENGTH - len(hashtags) - len(url) - 3\n",
    "        trimmed_summary = textwrap.shorten(summary, width=allowable, placeholder=\"...\")\n",
    "        full_tweet = f\"{title}\\n{trimmed_summary}\\n{url}\\n{hashtags}\"\n",
    "\n",
    "    return full_tweet.strip()\n",
    "\n",
    "# Preview loop\n",
    "\n",
    "for i, article in enumerate(articles[:3]):\n",
    "    for variant in [\"v1_summary\", \"v2_summary\"]:\n",
    "        tweet = format_tweet(article, variant)\n",
    "        print(f\"--- Tweet {i+1} ({variant}) ---\\n{tweet}\\n\\nCharacters: {len(tweet)}\\n\")\n",
    "\n",
    "# ðŸš€ Future options:\n",
    "# - Export tweets to .csv/.json\n",
    "# - Add editorial UI in notebook to rate/choose v1 vs v2\n",
    "# - Integrate this with Tweepy or a post scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae021889-98de-4658-af2e-b80916de4043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
